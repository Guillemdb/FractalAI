{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractalai.model import RandomDiscreteModel\n",
    "from fractalai.environment import ExternalProcess, ParallelEnvironment, AtariEnvironment\n",
    "from fractalai.swarm_wave import SwarmWave\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SwarmWave?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This algorithhm is made for solving discrete Markov decision processes when a perfect model is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this context, if you need to generate data to train a neural network, IO is now your bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"MsPacman-ram-v0\"\n",
    "skip_frames = 0  # Number of frames to skip at the beginning\n",
    "n_repeat_action = 4  # Apply the same action n times\n",
    "n_samples = 8 * 1e6  # Maximum number of samples allowed\n",
    "reward_limit = 10000  # Stop the sampling when this score is reached\n",
    "n_walkers = 500  # Maximum witdh of the tree containing al the trajectories\n",
    "render_every = 10  # print statistics every n iterations.\n",
    "balance = 1  # Balance exploration vs exploitation\n",
    "save_data = True # Save the data generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ParallelEnvironment(name=name,env_class=AtariEnvironment,\n",
    "                          blocking=False, n_workers=8, n_repeat_action=n_repeat_action)  # We will play an Atari game\n",
    "model = RandomDiscreteModel(max_wakers=n_walkers,\n",
    "                            n_actions=env.n_actions, samples=10000) # The Agent will take discrete actions at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: MsPacman-ram-v0 | Walkers: 500 | Deaths: 0\n",
      "Total samples: 1086151 Progress: 100.01%\n",
      "Reward: mean 9975.64 | Dispersion: 71.00 | max 10001.00 | min 9930.00 | std 12.82\n",
      "Episode length: mean 2241.73 | Dispersion 20.00 | max 2253.00 | min 2233.00 | std 4.42\n",
      "Status: Score limit reached.\n",
      "Efficiency 0.52%\n",
      "Generated 5682 Examples | 191.16 samples per example.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = SwarmWave(model=model, env=env, n_walkers=n_walkers, reward_limit=reward_limit, render_every=2, balance=balance, save_data=save_data)\n",
    "s.run_swarm(print_swarm=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.render_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
